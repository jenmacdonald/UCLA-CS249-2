{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 -- Diamonds\n",
    "## Due Sunday May 21, at 11:55pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jennifer MacDonald 604501712\n",
    "\n",
    "CS249 -- Spring 2017 -- D.S. Parker &copy; 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Overview\n",
    "\n",
    "The goal of this assignment is for you to develop models for the <a href=\"http://docs.ggplot2.org/current/diamonds.html\"><b>diamonds</b> dataset</a>,\n",
    "which is included in the <a href=\"http://ggplot2.org\">ggplot2</a> package.\n",
    "\n",
    "This is a very simple assignment:  you are asked to build four models:\n",
    "LDA or QDA, simple Linear Regression, log-scaled Linear Regression, and Logistic Regression.\n",
    "You then just upload the formulas (R commands) you used to construct these models to CCLE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of the numeric.diamonds Dataset\n",
    "\n",
    "## Transformed dataset for building all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need the ggplot2 package to get the \"diamonds\" dataset\n",
    "\n",
    "not.installed <- function(pkg) !is.element(pkg, installed.packages()[,1])\n",
    "\n",
    "if (not.installed(\"ggplot2\")) install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "    \n",
    "# library(devtools)\n",
    "# install_github(\"ggbiplot\", \"vqv\")\n",
    "     \n",
    "data(diamonds, package=\"ggplot2\") \n",
    "\n",
    "# load the MASS package, which includes simple implementations of LDA and QDA\n",
    "\n",
    "not.installed <- function(pkg) !is.element(pkg, installed.packages()[,1])\n",
    "\n",
    "if (not.installed(\"MASS\"))  install.packages(\"MASS\")  # we need the MASS package\n",
    "library(MASS)  #  load the MASS package   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Accuracy of Models in this Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of an LDA or QDA model is the percentage of correct classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_accuracy = function( model, test.data, test.solutions ) {\n",
    "    # The value is a vector or matrix of predicted values corresponding to the determining variable values in \n",
    "    # data.frame\n",
    "    predictions = predict( model, newdata = test.data )\n",
    "    \n",
    "    # check whether the predicted values in \"cut\" are the same as the actual values\n",
    "    incorrect.predictions  =  (predictions$class != test.solutions )\n",
    "    \n",
    "    # get the place and value of the incorrect predictions\n",
    "    incorrect.ids = test.solutions[incorrect.predictions]\n",
    "    \n",
    "    # subtract the incorrect values from the total length and divide by the length of the total to get the percentage\n",
    "    # or correct classification\n",
    "    accuracy = (length(test.solutions) - length(incorrect.ids)) / length(test.solutions)\n",
    "    \n",
    "    return (accuracy)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of a Linear Regression model is its R<sup>2</sup> value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_regression_accuracy = function( model, test.data, test.solutions ) {\n",
    "    predictions = predict( model, newdata = test.data )\n",
    "    \n",
    "    # Extract the regression coefficient (matrix)\n",
    "    intercept = coef(model)[\"(Intercept)\"] \n",
    "    \n",
    "    # calculate r-squared\n",
    "    accuracy = Rsquared(test.solutions, predictions, intercept)\n",
    "    \n",
    "    return (accuracy) \n",
    "}\n",
    "\n",
    "Rsquared = function (y, yhat, intercept) {\n",
    "    RSS = sum((y-yhat)^2) # residual sum of squares\n",
    "    if (intercept) { MSS = sum((yhat-mean(yhat))^2) } # model has an intercept\n",
    "    else { MSS = sum((yhat)^2) } # model does not have an intercept\n",
    "    return(MSS/(MSS + RSS)) # return muliple r-squared\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of a Logistic Regression model is the percentage of correct classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic_regression_accuracy = function( model, test.data, test.solutions ) {\n",
    "    predictions = predict( model, newdata = test.data, type = \"response\") \n",
    "    PredictionClasses = round(predictions) # Turn the numeric values into {0,1} values\n",
    "    \n",
    "    incorrect.predictions = (PredictionClasses != test.solutions)\n",
    "    \n",
    "    # Matrix charting performance of classifications \n",
    "    confusion.matrix = table( PredictionClasses, test.solutions ) \n",
    "    \n",
    "    accuracy = sum(diag(confusion.matrix)) / nrow(test.data)\n",
    "    \n",
    "    return (accuracy)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diamonds = subset( diamonds, (x>0) & (y>0) & (z>0) )  #  There are actually some zero values, we omit them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the categorical values to integers -- using the unclass() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric.diamonds = transform( diamonds,\n",
    "                              cut = as.numeric(unclass(diamonds$cut)),\n",
    "                              color = as.numeric(unclass(diamonds$color)),\n",
    "                              clarity = as.numeric(unclass(diamonds$clarity))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a training set and test set (as subsets of numeric.diamonds) -- using your UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MY_UID = 604501712 ########## you must enter your UCLA UID here !!!\n",
    "set.seed( MY_UID )\n",
    "n = nrow( numeric.diamonds )\n",
    "sample.size = 0.75 * n   ###### Use 75% of the data for the training set\n",
    "training.row.ids = sample( (1:n), sample.size )\n",
    "\n",
    "my.training.set = numeric.diamonds[  training.row.ids, ]\n",
    "my.test.set     = numeric.diamonds[ -training.row.ids, ]   # set complement of training.set.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute accuracy of 4 Baseline Models about diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a QDA classification model that predicts a diamond's Cut\n",
    "baseline_m1 = qda( cut ~ .,           data=my.training.set )\n",
    "baseline_m1_accuracy = classification_accuracy(baseline_m1, my.test.set, my.test.set$cut)\n",
    "\n",
    "# a linear regression model that predicts a diamond's Price\n",
    "baseline_m2 = lm(  price ~ .,         data=my.training.set )\n",
    "baseline_m2_accuracy = linear_regression_accuracy( baseline_m2, my.test.set, my.test.set$price )\n",
    "\n",
    "# a linear regression model that predicts a diamond's log10(Price)\n",
    "baseline_m3 = lm(  log10(price) ~ .,  data=my.training.set )\n",
    "baseline_m3_accuracy = linear_regression_accuracy( baseline_m3, my.test.set, log10(my.test.set$price) )\n",
    "\n",
    "# a logistic regression model that predicts whether a diamond's Price is above $1500\n",
    "baseline_m4 = suppressWarnings( glm( I(price>1500) ~ ., data=my.training.set, family=binomial ))\n",
    "baseline_m4_accuracy = logistic_regression_accuracy( baseline_m4, my.test.set, I(my.test.set$price>1500) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 4 Models improving on the Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  The Baseline models:\n",
    "\n",
    "m1 = qda( cut ~ price + table + color + clarity,       data=my.training.set )\n",
    "m1_accuracy = classification_accuracy(m1, my.test.set, my.test.set$cut)\n",
    "\n",
    "m2 = lm(  price ~ (carat + cut + clarity + color)^2,         data=my.training.set )\n",
    "m2_accuracy = linear_regression_accuracy(m2, my.test.set, my.test.set$price)\n",
    "\n",
    "m3 = lm(  log10(price) ~ (carat * cut * clarity * color * x * y * z)^2, data=my.training.set )\n",
    "m3_accuracy = linear_regression_accuracy(m3, my.test.set, log10(my.test.set$price))\n",
    "\n",
    "m4 = suppressWarnings( glm( I(price>1500) ~ carat * cut * clarity * color * x * y * z,     data=my.training.set, family = binomial ))\n",
    "m4_accuracy = logistic_regression_accuracy(m4, my.test.set, I(my.test.set$price>1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the accuracy of the Baseline and Improved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5537834 , qda( cut ~ .,           data=my.training.set )\n",
      "0.9078241 , lm(  price ~ .,         data=my.training.set )\n",
      "0.9768911 , lm(  log10(price) ~ .,  data=my.training.set )\n",
      "0.9798961 , glm( I(price>1500) ~ ., data=my.training.set, family=binomial )\n",
      "0.603635 , qda( cut ~ price + table + color + clarity,                           data=my.training.set )\n",
      "0.9283409 , lm( price ~ (carat + cut + clarity + color )^2 ),                     data=my.training.set )\n",
      "0.9861304 , lm(  log10(price) ~ (carat * cut * clarity * color * x * y * z )^2 ), data=my.training.set )\n",
      "0.9860534 , glm( I(price>1500) ~ carat * cut * clarity * color * x * y * z, )     data=my.training.set, family = binomial )"
     ]
    }
   ],
   "source": [
    "cat(baseline_m1_accuracy, \", qda( cut ~ .,           data=my.training.set )\\n\")\n",
    "cat(baseline_m2_accuracy, \", lm(  price ~ .,         data=my.training.set )\\n\")\n",
    "cat(baseline_m3_accuracy, \", lm(  log10(price) ~ .,  data=my.training.set )\\n\")\n",
    "cat(baseline_m4_accuracy, \", glm( I(price>1500) ~ ., data=my.training.set, family=binomial )\\n\")\n",
    "\n",
    "cat(m1_accuracy, \", qda( cut ~ price + table + color + clarity,                           data=my.training.set )\\n\")\n",
    "cat(m2_accuracy, \", lm( price ~ (carat + cut + clarity + color )^2 ),                     data=my.training.set )\\n\")\n",
    "cat(m3_accuracy, \", lm(  log10(price) ~ (carat * cut * clarity * color * x * y * z )^2 ), data=my.training.set )\\n\")\n",
    "cat(m4_accuracy, \", glm( I(price>1500) ~ carat * cut * clarity * color * x * y * z, )     data=my.training.set, family = binomial )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
