{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6:  Analyzing Data Science in the StackOverflow Tech Job Survey\n",
    "## Due Sunday June 4, at 11:55pm\n",
    "\n",
    "For this problem, extract part of the data involving <i>data science</i> and do two things:\n",
    "(1) build a regression model to predict salary, and\n",
    "(2) build a classifier model to predict the job title (\"occupation\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jennifer MacDonald 604501712\n",
    "\n",
    "CS249 -- Spring 2017 -- D.S. Parker &copy; 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\jenni\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "# Libraries for preprocessing, modeling, and calulating the data\n",
    "from sklearn import ensemble, linear_model, preprocessing, metrics \n",
    "from sklearn.cross_validation import train_test_split # For splitting the data into train and test\n",
    "from sklearn.metrics import mean_squared_error # For calculating mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0:  Getting the Survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JobSurvey = pd.read_csv('2016 Stack Overflow Survey Responses.csv') \n",
    "\n",
    "# Drop all rows with null values from star_wars_vs_star_trek column since so many are null\n",
    "JobSurvey['star_wars_vs_star_trek'] = JobSurvey['star_wars_vs_star_trek'].fillna('') \n",
    "JobSurvey = JobSurvey.dropna() # drop all rows with null values from JobSurvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = JobSurvey.copy() # Copy dataframe to manipulate without changing the original\n",
    "\n",
    "# Extract a subset of the data involving data science\n",
    "df1 = df[df.occupation == 'Business intelligence or data warehousing expert']\n",
    "df2 = df[df.occupation == 'Data scientist']\n",
    "df3 = df[df.occupation == 'Developer with a statistics or mathematics background']\n",
    "df4 = df[df.occupation == 'Machine learning developer']\n",
    "\n",
    "frames = [df1,df2,df3,df4]\n",
    "\n",
    "DataScience = pd.concat(frames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder() # Preprocess data by changing all categorical variables to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:  Predicting Salary\n",
    "\n",
    "The texts in this course have presented a number of regression models for predicting numeric values.\n",
    "\n",
    "Develop a \"regression\" model that predicts the <b>salary_midpoint</b> value (i.e., column number 15).\n",
    "\n",
    "You should use \"MSE\" (Minimum Squared Error) as the accuracy measure.\n",
    "Develop a model that reduces this error measure.\n",
    "\n",
    "This is asking you to produce the best model you can for each of the two datasets\n",
    "-- with the highest possible accuracy.\n",
    "In other words, you are asked to produce to models, and report the accuracy of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingRegressor() # Use Gradient Boosting for regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model for the JobSurvey dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JobSurvey_regr = JobSurvey.copy()\n",
    "\n",
    "JS_X_regr_pp = JobSurvey_regr.drop('salary_midpoint', axis=1) # Drop salary_midpoint (used as target instead)\n",
    "JS_X_regr =  JS_X_regr_pp.apply(le.fit_transform) # Apply preprocessing to data\n",
    "JS_y_regr = JobSurvey['salary_midpoint'] # Use salary_midpoint for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the JobSurvey dataset: 12366231.1939\n"
     ]
    }
   ],
   "source": [
    "# Split train and test data\n",
    "JS_X_regr_train, JS_X_regr_test, JS_y_regr_train, JS_y_regr_test = train_test_split(JS_X_regr, JS_y_regr) \n",
    "\n",
    "# Fit training data\n",
    "JS_regr_fit = clf.fit(JS_X_regr_train, JS_y_regr_train)\n",
    "# Make predictions from the training data onto the testing data\n",
    "JS_y_regr_pred = JS_regr_fit.predict(JS_X_regr_test)\n",
    "\n",
    "# Calculate mean squared error for the true vs. predicted values\n",
    "print('MSE for the JobSurvey dataset:', mean_squared_error(JS_y_regr_test, JS_y_regr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model for the DataScience dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat the process for the DataScience dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataScience_regr = DataScience.copy()\n",
    "\n",
    "DS_X_regr_pp = DataScience_regr.drop('salary_midpoint', axis=1)\n",
    "DS_X_regr =  DS_X_regr_pp.apply(le.fit_transform)\n",
    "DS_y_regr = DataScience['salary_midpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the DataScience dataset: 20407383.593\n"
     ]
    }
   ],
   "source": [
    "DS_X_regr_train, DS_X_regr_test, DS_y_regr_train, DS_y_regr_test = train_test_split(DS_X_regr, DS_y_regr)\n",
    "\n",
    "DS_regr_fit = clf.fit(DS_X_regr_train, DS_y_regr_train)\n",
    "DS_y_regr_pred = DS_regr_fit.predict(DS_X_regr_test)\n",
    "\n",
    "print('MSE for the DataScience dataset:', mean_squared_error(DS_y_regr_test, DS_y_regr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Predicting Job Satisfaction\n",
    "\n",
    "All of the tools covered in this course provide a large number of classifiers.\n",
    "\n",
    "Develop a classifier model that predicts the <b>job satisfaction</b> value (i.e., column number 27).\n",
    "\n",
    "More specifically, predict whether the value is <tt>\"I love my job\"</tt>.\n",
    "\n",
    "Please use \"accuracy rate\" (percentage of correct predictions) as the measure of accuracy for this analysis.\n",
    "For each of the two datasets, develop the best model you can -- with the highest possible accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression() # Use Logistic Regression for classification model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model for the JobSurvey dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JobSurvey_cls = JobSurvey.copy()\n",
    "# Change target data ('I love my job') to boolean 1 and all other responses to boolean 0\n",
    "JobSurvey_cls['job_satisfaction'] = (JobSurvey_cls['job_satisfaction'] == 'I love my job').astype(int) \n",
    "\n",
    "JS_X_cls_pp = JobSurvey_cls.drop('job_satisfaction', axis=1) # Drop job_satisfaction (use as target instead)\n",
    "JS_X_cls = JS_X_cls_pp.apply(le.fit_transform)\n",
    "\n",
    "JS_y_cls = JobSurvey_cls['job_satisfaction'] # Use job_satisfaction for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the JobSurvey dataset: 0.744902205576\n"
     ]
    }
   ],
   "source": [
    "JS_X_cls_train, JS_X_cls_test, JS_y_cls_train, JS_y_cls_test = train_test_split(JS_X_cls, JS_y_cls)\n",
    "\n",
    "JS_cls_fit = logistic.fit(JS_X_cls_train, JS_y_cls_train)\n",
    "JS_y_cls_pred = JS_cls_fit.predict(JS_X_cls_test)\n",
    "\n",
    "# Calculate percentage of correct predictions from the true y values of the test data\n",
    "print('Accuracy for the JobSurvey dataset:', metrics.accuracy_score(JS_y_cls_test, JS_y_cls_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model for the DataScience dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataScience_cls = DataScience.copy()\n",
    "DataScience_cls['job_satisfaction'] = (DataScience_cls['job_satisfaction'] == 'I love my job').astype(int)\n",
    "\n",
    "DS_X_cls_pp = DataScience_cls.drop('job_satisfaction', axis=1)\n",
    "DS_X_cls = DS_X_cls_pp.apply(le.fit_transform)\n",
    "\n",
    "DS_y_cls = DataScience_cls['job_satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the DataScience dataset: 0.681818181818\n"
     ]
    }
   ],
   "source": [
    "DS_X_cls_train, DS_X_cls_test, DS_y_cls_train, DS_y_cls_test = train_test_split(DS_X_cls, DS_y_cls)\n",
    "\n",
    "DS_cls_fit = logistic.fit(DS_X_cls_train, DS_y_cls_train)\n",
    "DS_y_cls_pred = DS_cls_fit.predict(DS_X_cls_test)\n",
    "\n",
    "print('Accuracy for the DataScience dataset:', metrics.accuracy_score(DS_y_cls_test, DS_y_cls_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
